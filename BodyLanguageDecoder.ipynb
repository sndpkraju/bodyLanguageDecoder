{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab63532",
   "metadata": {},
   "source": [
    "## 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5f2e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.8.7.3)\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.3.3)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.24.2)\n",
      "Requirement already satisfied: wheel in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (0.37.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (0.13.0)\n",
      "Requirement already satisfied: opencv-contrib-python in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (1.21.2)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mediapipe) (3.18.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->mediapipe) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2937eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp #import mediapipe\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e58e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils #drawing helpers\n",
    "mp_holistic = mp.solutions.holistic #mediapipe solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4958d",
   "metadata": {},
   "source": [
    "## 1. Make Some Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be70e54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image.flags.writable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        #image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28403049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999454021453857"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe63d9",
   "metadata": {},
   "source": [
    "## 2. Capture Landmarks and Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc5971e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d763cea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8320d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b09ca1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2e189371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"YAY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d2dc5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image.flags.writable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        #image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract pose landmarks\n",
    "            pose=results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in pose]).flatten())\n",
    "            # extract face landmarks\n",
    "            face=results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            #concat face and pose rows\n",
    "            row = pose_row +face_row\n",
    "            row.insert(0,class_name)\n",
    "            \n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa51696",
   "metadata": {},
   "source": [
    "## 3. Train Custom model Using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4d7c3",
   "metadata": {},
   "source": [
    "### 3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1fed6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8560d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9261a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features= information we use to predict target\n",
    "#target = what we are trying to classify\n",
    "\n",
    "X = df.drop('class', axis = 1)\n",
    "y = df['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0b7af23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78acc21f",
   "metadata": {},
   "source": [
    "### 3.2 Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "66fc9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline #build an ML pipeline\n",
    "from sklearn.preprocessing import StandardScaler #standardizes data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f93e6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr': make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc': make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf': make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "10b6c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train,y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fe84319a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PowerStar', 'PowerStar', 'Happy', 'Sad', 'Happy', 'PowerStar',\n",
       "       'YAY', 'YAY', 'YAY', 'Happy', 'ButtaBomma', 'ButtaBomma',\n",
       "       'PowerStar', 'YAY', 'Happy', 'YAY', 'ButtaBomma', 'Happy',\n",
       "       'PowerStar', 'ButtaBomma', 'Sad', 'Happy', 'Sad', 'ButtaBomma',\n",
       "       'Happy', 'Happy', 'ButtaBomma', 'Sad', 'ButtaBomma', 'Happy',\n",
       "       'PowerStar', 'PowerStar', 'Happy', 'PowerStar', 'ButtaBomma',\n",
       "       'ButtaBomma', 'PowerStar', 'PowerStar', 'YAY', 'PowerStar', 'YAY',\n",
       "       'YAY', 'YAY', 'Sad', 'ButtaBomma', 'Happy', 'Happy', 'Sad', 'YAY',\n",
       "       'Happy', 'Happy', 'PowerStar', 'YAY', 'PowerStar', 'PowerStar',\n",
       "       'PowerStar', 'YAY', 'Happy', 'Happy', 'YAY', 'ButtaBomma',\n",
       "       'PowerStar', 'Sad', 'PowerStar', 'Sad', 'YAY', 'PowerStar',\n",
       "       'ButtaBomma', 'YAY', 'YAY', 'ButtaBomma', 'ButtaBomma', 'Happy',\n",
       "       'Sad', 'PowerStar', 'Sad', 'PowerStar', 'ButtaBomma', 'Happy',\n",
       "       'ButtaBomma', 'Sad', 'YAY', 'ButtaBomma', 'YAY', 'Happy', 'Sad',\n",
       "       'ButtaBomma', 'Happy', 'Sad', 'Sad', 'Sad', 'PowerStar', 'Sad',\n",
       "       'ButtaBomma', 'Sad', 'Happy', 'Sad', 'Happy', 'PowerStar', 'Sad',\n",
       "       'Happy', 'ButtaBomma', 'PowerStar', 'Sad', 'Happy', 'ButtaBomma',\n",
       "       'Sad', 'YAY', 'Sad', 'Sad', 'PowerStar', 'Sad', 'Happy', 'Sad',\n",
       "       'Happy', 'YAY', 'PowerStar', 'Sad', 'ButtaBomma', 'Sad', 'Happy',\n",
       "       'PowerStar', 'PowerStar', 'Happy', 'ButtaBomma', 'YAY', 'YAY',\n",
       "       'ButtaBomma', 'PowerStar', 'Sad', 'Happy', 'YAY', 'ButtaBomma',\n",
       "       'Happy', 'PowerStar', 'ButtaBomma', 'Happy', 'PowerStar', 'Happy',\n",
       "       'ButtaBomma', 'YAY', 'PowerStar', 'PowerStar', 'YAY', 'Happy',\n",
       "       'PowerStar', 'YAY', 'Happy', 'Sad', 'Happy', 'Happy', 'PowerStar',\n",
       "       'YAY', 'Happy', 'Happy', 'PowerStar', 'ButtaBomma', 'Sad',\n",
       "       'ButtaBomma', 'YAY', 'YAY', 'ButtaBomma', 'Happy', 'Happy', 'Sad',\n",
       "       'YAY', 'ButtaBomma', 'Happy', 'YAY', 'Happy', 'PowerStar',\n",
       "       'PowerStar', 'Sad', 'YAY', 'PowerStar', 'PowerStar', 'YAY', 'Sad',\n",
       "       'PowerStar', 'Sad', 'PowerStar', 'PowerStar', 'ButtaBomma',\n",
       "       'Happy', 'Sad', 'ButtaBomma', 'PowerStar', 'YAY', 'Sad',\n",
       "       'ButtaBomma', 'Sad', 'Sad', 'Happy', 'YAY', 'Happy', 'YAY', 'Sad',\n",
       "       'PowerStar', 'YAY', 'Happy', 'Sad', 'Sad', 'Happy', 'Happy', 'YAY',\n",
       "       'ButtaBomma', 'Happy', 'Sad', 'Happy', 'PowerStar', 'ButtaBomma',\n",
       "       'YAY', 'Happy', 'ButtaBomma', 'ButtaBomma', 'Sad', 'YAY', 'YAY',\n",
       "       'PowerStar', 'ButtaBomma', 'YAY', 'PowerStar', 'Sad', 'Sad', 'Sad',\n",
       "       'Sad', 'YAY', 'Happy', 'PowerStar', 'YAY', 'Happy', 'Sad',\n",
       "       'PowerStar', 'ButtaBomma', 'Sad', 'Sad', 'Sad', 'ButtaBomma',\n",
       "       'PowerStar', 'Sad', 'Happy', 'Happy', 'Happy', 'ButtaBomma',\n",
       "       'Happy', 'Happy', 'Sad', 'PowerStar', 'PowerStar', 'YAY',\n",
       "       'PowerStar', 'Sad', 'PowerStar', 'PowerStar', 'YAY', 'YAY',\n",
       "       'Happy', 'YAY', 'ButtaBomma', 'Happy', 'Happy', 'ButtaBomma',\n",
       "       'Happy', 'Happy', 'Sad', 'Sad', 'YAY', 'PowerStar', 'YAY',\n",
       "       'PowerStar', 'PowerStar', 'Sad', 'Sad', 'Happy', 'ButtaBomma',\n",
       "       'Happy', 'Happy', 'Sad', 'Happy', 'Happy', 'PowerStar', 'Sad',\n",
       "       'Sad', 'YAY', 'Sad', 'PowerStar', 'PowerStar', 'PowerStar', 'YAY',\n",
       "       'YAY', 'Happy', 'PowerStar', 'Happy', 'YAY', 'Happy', 'ButtaBomma',\n",
       "       'PowerStar', 'Happy', 'Sad', 'Happy', 'YAY', 'Happy', 'ButtaBomma'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a707f4b",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate and Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6e27fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # accuracy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fbc66266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9966996699669967\n",
      "rc 0.9966996699669967\n",
      "rf 0.9933993399339934\n",
      "gb 0.9933993399339934\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo,accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ae44a5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PowerStar', 'PowerStar', 'Happy', 'Sad', 'Happy', 'PowerStar',\n",
       "       'YAY', 'YAY', 'YAY', 'Happy', 'ButtaBomma', 'ButtaBomma',\n",
       "       'PowerStar', 'YAY', 'Happy', 'YAY', 'ButtaBomma', 'Happy',\n",
       "       'PowerStar', 'ButtaBomma', 'Sad', 'Happy', 'Sad', 'ButtaBomma',\n",
       "       'Happy', 'Happy', 'ButtaBomma', 'Sad', 'ButtaBomma', 'Happy',\n",
       "       'PowerStar', 'PowerStar', 'Happy', 'PowerStar', 'ButtaBomma',\n",
       "       'ButtaBomma', 'PowerStar', 'PowerStar', 'YAY', 'PowerStar', 'YAY',\n",
       "       'YAY', 'YAY', 'Sad', 'ButtaBomma', 'Happy', 'Happy', 'Sad', 'YAY',\n",
       "       'Happy', 'Happy', 'PowerStar', 'YAY', 'PowerStar', 'PowerStar',\n",
       "       'PowerStar', 'YAY', 'Happy', 'Happy', 'YAY', 'ButtaBomma',\n",
       "       'PowerStar', 'Sad', 'PowerStar', 'Sad', 'YAY', 'PowerStar',\n",
       "       'ButtaBomma', 'YAY', 'YAY', 'ButtaBomma', 'ButtaBomma', 'Happy',\n",
       "       'Sad', 'PowerStar', 'Sad', 'PowerStar', 'ButtaBomma', 'Happy',\n",
       "       'ButtaBomma', 'Sad', 'YAY', 'ButtaBomma', 'YAY', 'Happy', 'Sad',\n",
       "       'ButtaBomma', 'Happy', 'Sad', 'Sad', 'Sad', 'PowerStar', 'Sad',\n",
       "       'ButtaBomma', 'Sad', 'Happy', 'Sad', 'Happy', 'PowerStar', 'Sad',\n",
       "       'Happy', 'ButtaBomma', 'PowerStar', 'Sad', 'Happy', 'ButtaBomma',\n",
       "       'Sad', 'YAY', 'Sad', 'Sad', 'PowerStar', 'Sad', 'Happy', 'Sad',\n",
       "       'Happy', 'YAY', 'PowerStar', 'Sad', 'ButtaBomma', 'Sad', 'Happy',\n",
       "       'PowerStar', 'PowerStar', 'Happy', 'ButtaBomma', 'YAY', 'YAY',\n",
       "       'ButtaBomma', 'PowerStar', 'Sad', 'Happy', 'YAY', 'ButtaBomma',\n",
       "       'Happy', 'PowerStar', 'ButtaBomma', 'Happy', 'PowerStar', 'Happy',\n",
       "       'ButtaBomma', 'YAY', 'PowerStar', 'PowerStar', 'YAY', 'Happy',\n",
       "       'PowerStar', 'YAY', 'Happy', 'Sad', 'Happy', 'Happy', 'PowerStar',\n",
       "       'YAY', 'Happy', 'Happy', 'PowerStar', 'ButtaBomma', 'Sad',\n",
       "       'ButtaBomma', 'YAY', 'YAY', 'ButtaBomma', 'Happy', 'Happy', 'Sad',\n",
       "       'YAY', 'ButtaBomma', 'Happy', 'YAY', 'Happy', 'PowerStar',\n",
       "       'PowerStar', 'Sad', 'YAY', 'PowerStar', 'PowerStar', 'YAY', 'Sad',\n",
       "       'PowerStar', 'Sad', 'PowerStar', 'PowerStar', 'ButtaBomma',\n",
       "       'Happy', 'Sad', 'ButtaBomma', 'PowerStar', 'YAY', 'Sad',\n",
       "       'ButtaBomma', 'Sad', 'Sad', 'Happy', 'YAY', 'Happy', 'YAY', 'Sad',\n",
       "       'PowerStar', 'YAY', 'Happy', 'Sad', 'Sad', 'Happy', 'Happy', 'YAY',\n",
       "       'ButtaBomma', 'Happy', 'Sad', 'Happy', 'PowerStar', 'ButtaBomma',\n",
       "       'YAY', 'Happy', 'ButtaBomma', 'ButtaBomma', 'Sad', 'YAY', 'YAY',\n",
       "       'PowerStar', 'ButtaBomma', 'YAY', 'PowerStar', 'Sad', 'Sad', 'Sad',\n",
       "       'Sad', 'YAY', 'Happy', 'Sad', 'YAY', 'Happy', 'Sad', 'PowerStar',\n",
       "       'ButtaBomma', 'Sad', 'Sad', 'Sad', 'ButtaBomma', 'PowerStar',\n",
       "       'Sad', 'Happy', 'Happy', 'Happy', 'ButtaBomma', 'Happy', 'Happy',\n",
       "       'Sad', 'PowerStar', 'PowerStar', 'YAY', 'PowerStar', 'Sad',\n",
       "       'PowerStar', 'PowerStar', 'YAY', 'YAY', 'Happy', 'YAY',\n",
       "       'ButtaBomma', 'Happy', 'Happy', 'ButtaBomma', 'Happy', 'Happy',\n",
       "       'Sad', 'Sad', 'YAY', 'PowerStar', 'YAY', 'PowerStar', 'PowerStar',\n",
       "       'Sad', 'Sad', 'Happy', 'ButtaBomma', 'Happy', 'Happy', 'Sad',\n",
       "       'Happy', 'Happy', 'PowerStar', 'Sad', 'Sad', 'YAY', 'Sad',\n",
       "       'PowerStar', 'PowerStar', 'PowerStar', 'YAY', 'YAY', 'Happy',\n",
       "       'PowerStar', 'Happy', 'YAY', 'Happy', 'ButtaBomma', 'PowerStar',\n",
       "       'Happy', 'Sad', 'Happy', 'YAY', 'Happy', 'ButtaBomma'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bce87992",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl','wb') as f:\n",
    "   pickle.dump(fit_models['rf'],f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8943a58",
   "metadata": {},
   "source": [
    "## 4. Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "95d0d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl','rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "17407e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #image.flags.writable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        #image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract pose landmarks\n",
    "            pose=results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in pose]).flatten())\n",
    "            # extract face landmarks\n",
    "            face=results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            #concat face and pose rows\n",
    "            row = pose_row +face_row\n",
    "            \n",
    "            \n",
    "#             row.insert(0,class_name)\n",
    "            \n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row)\n",
    "\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            #print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)\n",
    "                                ),[640,480]).astype(int))\n",
    "            cv2.rectangle(image,(coords[0],coords[1]+5), (coords[0]+len(body_language_class)*20,coords[1]-30),(245,117,16),-1)\n",
    "            cv2.putText(image,body_language_class, coords,cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "            \n",
    "            #Status box\n",
    "            cv2.rectangle(image,(0,0),(250,60),(245,117,16),-1)\n",
    "            cv2.putText(image, 'CLASS',(95,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0), 1,cv2.LINE_AA)\n",
    "            cv2.putText(image,body_language_class.split(' ')[0],(90,40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, 'PROB',(15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0), 1,cv2.LINE_AA)\n",
    "            cv2.putText(image,str(round(body_language_prob[np.argmax(body_language_prob)],2)),(10,40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "            \n",
    "                        \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd264a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b5c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d4d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
